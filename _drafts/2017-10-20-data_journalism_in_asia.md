---
title: Method to the madness - How to write an Economist Leader
header:
  teaser: 'https://farm5.staticflickr.com/4076/4940499208_b79b77fb0a_z.jpg'
categories:
  - analysis
tags:
  - update
---

**A very distinct structure of the Economist Leader articles emerges, after careful analysis**

In this post, I aim to inspire other journalists and bloggers to apply it to tell their own arguments.

“The leader” is one of the most important products the magazine delivers every week for its print and online edition. A guide of its composition was shared by  editors in a training session some time ago (I worked at the paper in the past). I want to share with you some of the lessons because I think it could enrich the work of others in the profession.

Before going deeper into its structure, a brief discussion on what a leader is in the eyes of the paper: It is a device to tell the reader what is important, to help sharpen readers argument, and occasionally to change their minds. Even for professional journalists at the paper, some find it hard to write. A clear structure can be a remedy for any novice.

The Economist uses the leader for two reasons.
1. Importance of current events: to help readers understand current important situations, entanglement and explaining an agenda
2. Issues that faded into the background, but are worth it to dig up again: Events and topics that mostly aren’t news right now, but ought to be on readers’ agenda. It’s about saying that something matters, as much as it is about how suspiring its conclusion is.

A shorter description is offered: “If pieces are stories, leaders are arguments”. There is a sense of importance and this is why, many times, leader arguments make it on the cover. Cover story and leaders are connected.   

The leader wants to help readers to form their arguments. There are a number of ways those arguments are of importance. One of those argument-types is often referred to as “mind caring”.  This is mainly about untangling the mess of a specific event (see the leaders on Donald Trump, protectionism, major despots of our time … - the list is long).

It is also often the province of economic leaders, where many times contradictory arguments are being called out. Those leaders help to understand what’s important, and which of those matter most and are likely to win a debate.

The second type of leader is the “missing the point leader”.  Those will make the argument that the real problem around a topic is in fact buried somewhere else. Those leaders are fruitful, as one editor says. The leader on unintended consequences is a growing and rich theme (regulations that are supposed to make the world safer, but in fact have little or the opposite effect).

The Dodd Frank act, and the unintended consequences on the intent to kill the regulation, is an old example https://www.economist.com/news/leaders/21716607-make-rules-simpler-all-means-not-expense-safety-right-way-redo. Some of the best leaders written on ethics emerge from that direction.

A leader on murder wouldn’t be right and is likely boring - being boring is a cardinal sin, says one editor. The best leaders for example about ethics have the ability to surprise. Leaders on ethics, that have a counterintuitive or surprising conclusion (e.g. a leader on legalising prostitution).

Structure

Usually, a leader covers a number of basic elements. Sometimes authors decide to leave out components, sometimes building blocks appear in a slightly different way or sequence.

The basic components of a leader in the following sequence:
	•	Introduction: The start contains an enticing observation, and the theme
	•	News/contemporary event
	•	The nub
	•	Stand back
	•	Your arguments
	•	Their arguments
	•	What to do about it


While explaining each, let’s talk about an example from the current edition.

1. Introduction:
Most leaders begin with an observation, almost never is the start a statement of the news peg (it rarely works because it seems flat). Those very first thoughts are many times of an emotional nature.

They can be moving, funny and are enticing. Many times they go against the conclusion, may even provoke and correlate with the public opinion. Usually they are short, a little paragraph, both relevant and fitting to the core argument(s).  

The second component for the introduction is to state the theme; or answering: “What is this all about?”

2. News/contemporary event:
Here the author drops the news-peg. In the case of the “Sex and power” leader, it is New York Times investigation into Harvey Weinstein and his response to the allegations.

3. The nub - the punctuation point that sets up everything else to come:
Often missing, the first section of the leader ends with the nob. It is being described as giving the leader its momentum, the bit of tension in the argument and the part where the author states what’s wrong. An example is where the author of “Sex and power” writes: “A throwback who loves women too much, then; a sly old rogue who doubtless holds doors open for women, too? Nonsense. What Mr. Weinstein is accused of was never acceptable. It has never been good form to greet a woman arriving for a business meeting while wearing nothing but an open bathrobe”.

In a column piece, this bit can be included too, but usually further down. The characteristics of the leader pulls this section up, near the beginning (many times, it is right before the first crosshead, in our case before the crosshead “Not Safe For Women” - the crosshead marks usually the boundary between first section and rest). The nob draws readers in, and explains why to read this leader - Weinstein’s behavior was never acceptable.

4. Stepping-back and giving context and background:
This is the point when the author explains the context, historical entanglements and the chance to elaborate how we got here. For politics, many times readers get a history lesson. For an economics and business leader such as “Sex and power”, we are told about the 1970ties and 1980ties an offices with “Mad Men-style ordeal of leering eyes and roaming hands”.

5 and 6. Balance arguments:
Here you start the start the argument. Data journalists particularly, may have their fun here and drop their statistical arguments and throw around their arguments based on numbers. Show both a good balance between pro and contra arguments and keep it brief (usually, each paragraph here is a single argument).
The author carefully takes on the opponent’s argument, which usually a close observation of the pro-arguments can overtrump. As one editor explains, this section is an important part of the leader where the authors grapple with the good arguments against the overall argument. This, in my opinion, makes the leader a good and powerful medium for journalism. It requires to give a fair view.

7. Last bit of the leader: The prescription
This section describes the mess is short and offers possible solutions - an opportunity to respond to the collection of both pro and contra arguments. It requires the author to pull the very best of arguments. For the example of “Sex and Power”, it is the bit where the author writes that for sexual harassment to be stopped, it needs to be called out not just by the victims, but also by the witnesses.

Each leader’s narrative usually accounts for one page, around the 1,000 word mark (many times the topic are further extended in other parts of the paper). The US Election, Brexit, industries in transformation, all those are instances of topics leaders can embrace. They are brazing and prevailing affairs in the present news-landscape. To a greater or lesser extent, a leader settles a score with a person, an event or a trend, which usually isn’t just going away tomorrow or next week.

With the medium of those leaders, there is one of the company’s most important product: a exegesis of how to fathom the world. The magazine also delivers those in a single voice – there are no bylines. Hoping not to share the secret sauce of the paper, as a novice, learning the art of good journalism, I can only appreciate those lessons and use some of the rules for my very own pieces.  








<!-- <figure>
  <a href="https://i.ytimg.com/vi/pzwT6lQ0sHE/maxresdefault.jpg">
  <img src="https://i.ytimg.com/vi/pzwT6lQ0sHE/maxresdefault.jpg">
</a>
  <figcaption><a href="https://i.ytimg.com/vi/pzwT6lQ0sHE/maxresdefault.jpg" title="Street League 2013: Nyjah Huston">Street League 2013: Nyjah Huston</a>.</figcaption>
</figure> -->

<!-- Skateboarding has had a bad reputation for many years before Louis Vuitton used [it in their ads](https://www.youtube.com/watch?v=GWydT-BNbQo). Today, skateboarding manages to get attention from all corners of the media landscape, and is now even only one step away to become an [Olympic discipline](http://theridechannel.com/news/2016/06/skateboarding-olympics-tokyo-2020). For decades, the typical competition format was that skaters were judged on their run, however Street league Skateboarding established a whole new data driven model to judge the performance of each street skater.

Instead of only being ranked on the run on the skate course, SLS introduced a real time rating system, single tricks evaluation, and a statistical evaluation of the scoring for each skater.

![pic1]({{ site.url }}/images/sls/skatetrick.gif)

# Sh.t is going down this weekend, at the Nike SB Super Crown World Championship

This Sunday, the biggest street skateboarding competition will take place in LA. SLS is the official street skateboarding world championship as recognized by the International Skateboarding Federation. At the recent Street League Skateboarding Nike SB World Tour in Newark, New Jersey, [Nyjah Huston](http://streetleague.com/pros/nyjah-huston/) won the game and is now defending the 2015 SLS Championship title. Could we yield some interesting findings that could support skaters with empirical evidence how to win it?

![pic1]({{ site.url }}/images/sls/super_crown.png)

Via a simple [EDA](https://en.wikipedia.org/wiki/Exploratory_data_analysis), we will try to establish a number of relevant patterns gained from previous SLS results.

# Relationships

We understand from the correlation plot that there is a negative relationship between best-trick and run scores (-0.5), and an interesting one between age of skater and number of sponsors for each skater. Number of sponsors also plays nicely with final results for 2015 championship points.

![pic1]({{ site.url }}/images/sls/plots/correlation2.png)

# Strategy

Loess line seems to draw a different picture, than the linear regression line. We will consider the structure later, when building a prediction model.

SLS's competition format requires a lot more strategic planning today, than in the previous single score run-based competitions. An analysis of run-section and best-trick scores across recent Street League contests suggests that if players do perform well on either one of the sections, they usually perform not not as well in the other one (although, the linear trend is more significant for the preliminaries).

![pic1]({{ site.url }}/images/sls/plots/B_2.png)

Chaz Ortiz and Shane O'Neill know how to perform well in the run section (mainly due to their vast experience in conventional skate contests), while Kevin Hoefler and Manny Santiago do well in the best-trick section. All-rounders such as Nyjah Huston and Luan Oliveira seem to do well in both sections for the finals. For the preliminaries, Shane and Nyjah leading the field, and are able to make it into the finals every single time.

# Street League's evolution

Launched in 2010, Street League Skateboarding is now an international competitive series in professional skateboarding. The SLS ISX, which is the core of the concept, is best described as a real time scoring system, allowing to include each trick independently. This stands in contrast to all other professional contests that judge on overall impression of a full run or series of tricks performed within a certain time frame. Because the outcome could change to the very last trick, the audience is kept in their seats. Transparency is high too. If the audience is able to understand how and why the skaters were judged the way they were, it adds an additional kick. To win, skaters are required to to have a strategy and be smart about how they play their skills and their endurance.

![pic1]({{ site.url }}/images/sls/plots/C.png)

Comparing 2015 with 2016, Nyjah Huston's run scores dropped slightly (this could be due to the fact that the scoring changed overall).

![pic1]({{ site.url }}/images/sls/plots/D.png)

While Shane O'Neill could not improve on his highest run scores (but on best trick scores)...

![pic1]({{ site.url }}/images/sls/plots/E.png)

...Paul Rodriguez kept performing well across both sections.

If a skater is strikingly good at the run section, but fails to succeed in the best trick section (or vice versa), he (or she, female Street League was introduced in 2015) is unlikely to win.

So what is the best strategy? To answer the question, it helps to look at statistical coefficients and relationships for data points for the previous events.

# Can you predict win probabilities after the run section?

Ok, we learned something from a basic exploratory data analysis. It's time to shift our attention to machine learning and use what we learned.

Every SLS game starts with the run section, and ends with the best trick category. We could use machine learning and train one or multiple models to yield win probabilities after the run section, but before the best trick section and announcement of a winner to predict the winner.

In the next part our goal is to build multiple models, the practice to statistically compare them, and to come up with one that allows us to predict mid-game, which skater has the best changes to win the upcoming SLS Nike SB Super Crown World Championship.

## Defining Independent and dependent variables

The outcome variable we will predict is a win or no-win. An variation to this is building a classification models on podium winners (1st, 2nd, 3rd). In different corner of the SLS website, we find information on the [pro skaters](http://streetleague.com/pros/), their previous performances and [event-specific results](http://streetleague.com/coverage/new-jersey-2016/).

From the [SLS website](http://streetleague.com/the-9-club/), we scrape the number of 9 club scores for each skater (9 Club tricks are the most extraordinary moments in Street League and represents the highest scores in previous contest). 9 club scores may also be an important predictor on how well the players did perform in the best trick section.

Run HST and Run Avg may be important predictors to our models. Championship Points allow new and established skaters to qualify into the SLS Nike SB Super Crown World Championship. Each skater's point score will be fed to our model.

We also throw in additional parameters. We have access to the age of some of the established pro skaters (the average age of pros is around 25, but outliers such as Cole may skew it), we know their stance (goofy or regular), and in the process of scraping and cleaning, I was able to count the number of sponsors.

# Model types

We will build logic regression classification models, and compare how well they are able to perform against each other.

## Logic Regression

We will build and test a [binomial logistic regression](https://en.wikipedia.org/wiki/Binomial_regression) (our outcome variable which can assume 2 values). The following variables will be used to fit a [GLM](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/glm.html) model in R:

```r
# Overview of variables:
glimpse(win)
```

In a hidden process, I have cleaned the data, and converted them to required class types. Categorical data are factor values, while numerical are encoded as numerical or as an integer class. The age variable has no missing values anymore ([removal of NA values in R](http://stackoverflow.com/questions/7706876/remove-na-values-from-a-vector)), and they have been replaced with the average age values. Similarly, I dealt with the values in the stance column (to what degree this is valid, needs to be evaluated, but for now, we don't care too much about stance - in theory, it shouldn't make a difference whether a brilliant skater is goofy or regular).

![pic1]({{ site.url }}/images/sls/plots/lr_overview.png)

```r
# randomize, sample training and test set:
set.seed(10)
win_r <- sample_n(win, 207)

train <- win_r[1:150,]
test <- win_r[151:207,]

# fit GLM model:
model <- glm(class_winner ~.,family=binomial(link='logit'),data=train)
summary(model)
```

![pic1]({{ site.url }}/images/sls/plots/lr_fitting.png)

We learn from the summary function that most of the variables are not statistically significant for our model. Run_HST is possibly the best predictor we can use at this stage. A positive coefficient for Run_HST suggests - if other variables are kept equal - that a unit increase in highest run section scores would increase the odds to win by 4.740e+00.

We run a function from the Anova package, to investigate the table of deviance:

```r
anova(model, test="Chisq")
```

![pic1]({{ site.url }}/images/sls/plots/lr_deviance.png)

This gives us an idea on how well our GLM model performs agains the null model. Here we see that not only Run_HST reduced the residual deviance, but also the variables age and champ_pts_2015\. For us it is important to see a significant decrease in deviance. Lets assess the model's fit via McFadden R-Squared measure:

```r
install.packages("pscl")
library(pscl)
pR2(model)

llh          llhNull     G2           McFadden    r2ML        r2CU
-14.2949557 -36.7395040  44.8890966   0.6109105   0.2586338   0.6678078
```

This yields a McFadden score of 0.611, which might be comparable to a linear regression's R-Squared metric.

```r
# Run on test data:
test_run<-test %>%
  select(-class_winner)

fitted.results <- predict(model,test_run, type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)

misClasificError <- mean(fitted.results != test$class_winner)
misClasificError
print(paste('Accuracy',1-misClasificError))

#[1] "Accuracy 0.912280701754386"

#CrossTable:
CrossTable(fitted.results, test$class_winner,
prop.chisq = F, prop.t = F,
dnn = c("Predicted", "Actual"))
```

While we get an accuracy of 91%, this result is misleading. The model couldn't find who is going to win. Only who is not to win, which isn't really our problem at this stage, but one reason we get such high accuracy score.

![pic1]({{ site.url }}/images/sls/plots/lr_winner_poor.png)

```r
ctrl <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE)
mod_fit <- train(class_winner ~.,  data=win_r, method="glm", family="binomial",
                 trControl = ctrl, tuneLength = 5)

pred = predict(mod_fit, newdata=test)
confusionMatrix(data=pred, test$class_winner)
```

We can confirm the accuracy result with K-Fold cross validation, a central model performance metric in machine learning. We apply one of the most common variation of cross validation, the 10-fold cross-validation and display the result via a confusion matrix. Now we get an even higher accuracy score of 95 percent. Still, the model couldn't find the winners.

![pic1]({{ site.url }}/images/sls/plots/ls_cross_validation.png)

## Predicting winning a medal:

The data only covers two years of the games. This makes it hard for a model like this to spot winners. What we could be doing instead is to tune down our standards, and only look for the lucky three winners who make it onto a podium. For that, we need to calculate an extra column, and add a "1", for all skaters who made it among the top three, and "0" for the ones that didn't. To test our new model, we will run it on the most recent game in New Jersey, after cleaning the training data.

```r

set.seed(10)
win_r <- sample_n(test <- win[c(1:68, 77:207),], 199)

train <- win_r
test <- win[69:76,] ##New-Jersey-2016

model <- glm(top_3_outcome ~.,family=binomial(link='logit'),data=train)

test_run<-test %>%
  select(-top_3_outcome)

fitted.results <- predict(model,test_run, type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)

misClasificError <- mean(fitted.results != test$top_3_outcome)
print(paste('Accuracy',1-misClasificError))

#[1] "Accuracy 0.75"

#CrossTable:
CrossTable(fitted.results, test$top_3_outcome,
prop.chisq = F, prop.t = F,
dnn = c("Predicted", "Actual"))
```

![pic1]({{ site.url }}/images/sls/plots/jersey.png)

This model performs better. Except of 2 miss-classified instances, we got 2 out of 3 podium winners right. While it did well on the two winners - Nyjah Huston (1st), Chris Joslin (2nd), with 90% and 80% probability respectively - the model could not figure out the third place, that was labelled as "other" in our training data. Tommy Fynn was not included in the practice when I labelling the rank_skater column (skaters that will play Sunday's finals were labelled in the data). As good practice requires, we will look at is ROC curve to produce a visual representation for the AUC, a performance measurements for a binary classifier.

```r
install.packages("ROCR")
library(ROCR)
fitted.results <- predict(model,test_run, type='response')
fitted_for_ROCR <- prediction(fitted.results, test$top_3_outcome)
performance_ROCR <- performance(pr, measure = "tpr", x.measure = "fpr")

# plot:
plot(prf)

AUC <- performance(fitted.results, measure = "auc")
AUC <- auc@y.values[[1]]
#[1] 0.7333333
```

![pic1]({{ site.url }}/images/sls/plots/ROCR.png)

An AUC of 0.73 is not entirely pleasing, but it's a start. We could now look for which score each skater on Sunday would need to gain for decent win probability. For this, we could build a test-set with the skater names and run scores ranging from 1 to 10 (we already know that skater and Run_HST are powerful predictors for the podium medals).

```r
### probabilities for highest scores:
scores <- seq(1, 10, 0.1)

skaters <- c("NyjahHuston", "ShaneONeill", "PaulRodriguez",
             "LuanOliveira", "TomAsta", "RyanDecenzo", "CodyMcEntire",
             "ChrisJoslin")

df_skate <- NULL
for (skater in 1:length(skaters)) {
  for (s in 1:length(scores)) {
    df_skate <- rbind(df_skate, cbind(as.data.frame(scores[s]), as.data.frame(skaters[skater])))
  }
}

  names(df_skate)[1] <- "Run_HST"
  names(df_skate)[2] <- "rank_skater"

  fitted.results <- predict(model,df_skate, type='response') # with Run_HST and rank_skater as input variables

  ggplot(props, aes(Run_HST, fitted.results, group = rank_skater, col = rank_skater)) +
    geom_line() + theme_minimal()
```

![pic1]({{ site.url }}/images/sls/plots/props_skaters_lr.png)

Win probabilities chart for each skater from their highest run scores.

# Wrapping up

As we have seen, Nyjah Huston, Shane O'Neill and Paul Rodriguez do have best chances to make it on the podium. In which combination is unclear, but we will find out shortly. We have also learned how to apply a logistic regression on skateboarding, and how to compare the results across the various types of models we build. Two more models have been built. A neural network model and a random forrest model, both which didn't perform as well as the logistic regression. -->
